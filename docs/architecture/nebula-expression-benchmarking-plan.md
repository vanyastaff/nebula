# Nebula Expression - Benchmarking Plan

> **–¶–µ–ª—å**: –°–æ–∑–¥–∞—Ç—å comprehensive benchmark suite –¥–ª—è –∏–∑–º–µ—Ä–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ —É–ª—É—á—à–µ–Ω–∏–π

---

## üéØ –ó–∞—á–µ–º –±–µ–Ω—á–º–∞—Ä–∫–∏ –ø–µ—Ä–≤—ã–º–∏?

### –ü—Ä–æ–±–ª–µ–º–∞ –±–µ–∑ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤

```
‚ùå "–ö–∞–∂–µ—Ç—Å—è —Å—Ç–∞–ª–æ –±—ã—Å—Ç—Ä–µ–µ"
‚ùå "–ù–∞–≤–µ—Ä–Ω–æ–µ –º–µ–Ω—å—à–µ –∞–ª–ª–æ–∫–∞—Ü–∏–π"
‚ùå "–í—Ä–æ–¥–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –ª—É—á—à–µ"
```

### –° –±–µ–Ω—á–º–∞—Ä–∫–∞–º–∏

```
‚úÖ Template parse: 10.2Œºs ‚Üí 2.1Œºs (4.86x faster)
‚úÖ Allocations: 15 ‚Üí 3 per eval (5x reduction)
‚úÖ Concurrent throughput: 9,847 ‚Üí 74,123 ops/sec (7.53x)
```

---

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤

```
crates/nebula-expression/
‚îú‚îÄ‚îÄ benches/
‚îÇ   ‚îú‚îÄ‚îÄ template.rs           # Template parsing & rendering
‚îÇ   ‚îú‚îÄ‚îÄ engine.rs             # Expression evaluation
‚îÇ   ‚îú‚îÄ‚îÄ lexer.rs              # Tokenization
‚îÇ   ‚îú‚îÄ‚îÄ parser.rs             # AST construction
‚îÇ   ‚îú‚îÄ‚îÄ eval.rs               # Evaluation
‚îÇ   ‚îú‚îÄ‚îÄ concurrent.rs         # Concurrent access
‚îÇ   ‚îú‚îÄ‚îÄ memory.rs             # Allocation tracking
‚îÇ   ‚îî‚îÄ‚îÄ builtins.rs           # Built-in functions
‚îú‚îÄ‚îÄ Cargo.toml                # criterion dependency
‚îî‚îÄ‚îÄ README.md
```

---

## üîß Setup

### 1. –î–æ–±–∞–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

```toml
# Cargo.toml

[dev-dependencies]
criterion = { version = "0.5", features = ["html_reports"] }
dhat = "0.3"  # Heap allocation profiler

[[bench]]
name = "template"
harness = false

[[bench]]
name = "engine"
harness = false

[[bench]]
name = "concurrent"
harness = false

[[bench]]
name = "memory"
harness = false
```

---

## üìä Benchmark Suite

### 1. Template Benchmarks

**–§–∞–π–ª**: `benches/template.rs`

**–ß—Ç–æ –∏–∑–º–µ—Ä—è–µ–º**:
- Parse time (simple/complex templates)
- Render time
- Memory allocations
- Clone performance

```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion, BenchmarkId};
use nebula_expression::{Template, ExpressionEngine, EvaluationContext};
use nebula_value::Value;

fn benchmark_template_parse(c: &mut Criterion) {
    let mut group = c.benchmark_group("template_parse");

    // Simple template
    group.bench_function("simple", |b| {
        b.iter(|| {
            Template::new(black_box("Hello {{ $input }}!"))
        })
    });

    // Complex template with multiple expressions
    group.bench_function("complex", |b| {
        let template = r#"
            <html>
                <title>{{ $workflow.name }}</title>
                <body>
                    <h1>{{ $execution.id }}</h1>
                    <p>Result: {{ $input | uppercase() }}</p>
                    <span>{{ $node.data.count * 2 }}</span>
                </body>
            </html>
        "#;
        b.iter(|| {
            Template::new(black_box(template))
        })
    });

    // Real-world template
    group.bench_function("realistic", |b| {
        let template = include_str!("../tests/fixtures/email_template.html");
        b.iter(|| {
            Template::new(black_box(template))
        })
    });

    group.finish();
}

fn benchmark_template_render(c: &mut Criterion) {
    let mut group = c.benchmark_group("template_render");

    let engine = ExpressionEngine::new();
    let mut context = EvaluationContext::new();
    context.set_input(Value::text("World"));

    let simple = Template::new("Hello {{ $input }}!").unwrap();
    let complex = Template::new(r#"
        <html>
            <title>{{ $input | uppercase() }}</title>
            <p>{{ $input | length() }}</p>
        </html>
    "#).unwrap();

    group.bench_function("simple", |b| {
        b.iter(|| {
            simple.render(black_box(&engine), black_box(&context))
        })
    });

    group.bench_function("complex", |b| {
        b.iter(|| {
            complex.render(black_box(&engine), black_box(&context))
        })
    });

    group.finish();
}

fn benchmark_template_clone(c: &mut Criterion) {
    let template = Template::new("Hello {{ $input }}!").unwrap();

    c.bench_function("template_clone", |b| {
        b.iter(|| {
            black_box(template.clone())
        })
    });
}

criterion_group!(
    benches,
    benchmark_template_parse,
    benchmark_template_render,
    benchmark_template_clone
);
criterion_main!(benches);
```

---

### 2. Engine Benchmarks

**–§–∞–π–ª**: `benches/engine.rs`

**–ß—Ç–æ –∏–∑–º–µ—Ä—è–µ–º**:
- Evaluation time (cached vs uncached)
- Different expression types
- Cache hit rate

```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion, BenchmarkId};
use nebula_expression::{ExpressionEngine, EvaluationContext};
use nebula_value::Value;

fn benchmark_evaluate_no_cache(c: &mut Criterion) {
    let mut group = c.benchmark_group("evaluate_no_cache");

    let engine = ExpressionEngine::new();
    let context = EvaluationContext::new();

    let expressions = vec![
        ("literal", "42"),
        ("arithmetic", "2 + 3 * 4"),
        ("comparison", "10 > 5"),
        ("string_concat", "\"hello\" + \" \" + \"world\""),
        ("function_call", "uppercase('hello')"),
        ("nested", "abs(min(-5, -10)) * 2"),
    ];

    for (name, expr) in expressions {
        group.bench_with_input(BenchmarkId::from_parameter(name), expr, |b, expr| {
            b.iter(|| {
                engine.evaluate(black_box(expr), black_box(&context))
            })
        });
    }

    group.finish();
}

fn benchmark_evaluate_with_cache(c: &mut Criterion) {
    let mut group = c.benchmark_group("evaluate_with_cache");

    let engine = ExpressionEngine::with_cache_size(1000);
    let context = EvaluationContext::new();

    let expr = "2 + 3 * 4";

    // Warm up cache
    let _ = engine.evaluate(expr, &context);

    group.bench_function("cache_hit", |b| {
        b.iter(|| {
            engine.evaluate(black_box(expr), black_box(&context))
        })
    });

    group.finish();
}

fn benchmark_cache_lookup(c: &mut Criterion) {
    let mut group = c.benchmark_group("cache_lookup");

    let engine = ExpressionEngine::with_cache_size(1000);
    let context = EvaluationContext::new();

    // Fill cache with different expressions
    for i in 0..100 {
        let _ = engine.evaluate(&format!("{} + {}", i, i + 1), &context);
    }

    group.bench_function("lookup", |b| {
        b.iter(|| {
            engine.evaluate(black_box("50 + 51"), black_box(&context))
        })
    });

    group.finish();
}

criterion_group!(
    benches,
    benchmark_evaluate_no_cache,
    benchmark_evaluate_with_cache,
    benchmark_cache_lookup
);
criterion_main!(benches);
```

---

### 3. Concurrent Benchmarks

**–§–∞–π–ª**: `benches/concurrent.rs`

**–ß—Ç–æ –∏–∑–º–µ—Ä—è–µ–º**:
- Concurrent throughput
- Lock contention
- Scalability

```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion, Throughput};
use nebula_expression::{ExpressionEngine, EvaluationContext};
use std::sync::Arc;
use std::thread;

fn benchmark_concurrent_access(c: &mut Criterion) {
    let mut group = c.benchmark_group("concurrent_access");

    let engine = Arc::new(ExpressionEngine::with_cache_size(1000));
    let expr = "2 + 2";

    // Single thread baseline
    group.bench_function("single_thread", |b| {
        let context = EvaluationContext::new();
        b.iter(|| {
            engine.evaluate(black_box(expr), black_box(&context))
        })
    });

    // Multi-threaded
    for num_threads in [2, 4, 8, 16] {
        group.bench_function(format!("{}_threads", num_threads), |b| {
            b.iter(|| {
                let handles: Vec<_> = (0..num_threads)
                    .map(|_| {
                        let engine = Arc::clone(&engine);
                        thread::spawn(move || {
                            let context = EvaluationContext::new();
                            for _ in 0..100 {
                                let _ = engine.evaluate(expr, &context);
                            }
                        })
                    })
                    .collect();

                for handle in handles {
                    handle.join().unwrap();
                }
            })
        });
    }

    group.finish();
}

fn benchmark_throughput(c: &mut Criterion) {
    let mut group = c.benchmark_group("throughput");
    group.throughput(Throughput::Elements(1));

    let engine = Arc::new(ExpressionEngine::with_cache_size(1000));

    group.bench_function("ops_per_sec", |b| {
        let context = EvaluationContext::new();
        b.iter(|| {
            engine.evaluate(black_box("2 + 2"), black_box(&context))
        })
    });

    group.finish();
}

criterion_group!(
    benches,
    benchmark_concurrent_access,
    benchmark_throughput
);
criterion_main!(benches);
```

---

### 4. Memory Benchmarks

**–§–∞–π–ª**: `benches/memory.rs`

**–ß—Ç–æ –∏–∑–º–µ—Ä—è–µ–º**:
- Heap allocations
- Memory usage
- Clone costs

```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion};
use nebula_expression::{Template, ExpressionEngine, EvaluationContext};
use nebula_value::Value;

#[global_allocator]
static ALLOC: dhat::Alloc = dhat::Alloc;

fn benchmark_allocations(c: &mut Criterion) {
    let mut group = c.benchmark_group("allocations");

    group.bench_function("template_parse", |b| {
        b.iter(|| {
            let _profiler = dhat::Profiler::new_heap();
            Template::new(black_box("Hello {{ $input }}!"))
        })
    });

    group.bench_function("template_render", |b| {
        let engine = ExpressionEngine::new();
        let mut context = EvaluationContext::new();
        context.set_input(Value::text("World"));
        let template = Template::new("Hello {{ $input }}!").unwrap();

        b.iter(|| {
            let _profiler = dhat::Profiler::new_heap();
            template.render(black_box(&engine), black_box(&context))
        })
    });

    group.bench_function("evaluate", |b| {
        let engine = ExpressionEngine::new();
        let context = EvaluationContext::new();

        b.iter(|| {
            let _profiler = dhat::Profiler::new_heap();
            engine.evaluate(black_box("2 + 2"), black_box(&context))
        })
    });

    group.finish();
}

fn benchmark_clone_costs(c: &mut Criterion) {
    let mut group = c.benchmark_group("clone_costs");

    let mut context = EvaluationContext::new();
    context.set_input(Value::integer(42));
    for i in 0..100 {
        context.set_execution_var(&format!("var_{}", i), Value::integer(i));
    }

    group.bench_function("context_clone", |b| {
        b.iter(|| {
            black_box(context.clone())
        })
    });

    group.finish();
}

criterion_group!(
    benches,
    benchmark_allocations,
    benchmark_clone_costs
);
criterion_main!(benches);
```

---

## üéØ Baseline Metrics (Current State)

–ü–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤ —Å–æ–∑–¥–∞–¥–∏–º baseline:

```bash
# Run all benchmarks
cargo bench --package nebula-expression

# Save baseline
cargo bench --package nebula-expression -- --save-baseline before-p0
```

### –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (BEFORE)

```
Template:
  parse/simple:        10.2 Œºs
  parse/complex:       45.8 Œºs
  render/simple:       8.5 Œºs
  clone:              2.1 Œºs

Engine:
  evaluate_no_cache:  48.3 Œºs
  evaluate_cached:    12.7 Œºs
  cache_lookup:       150 ns

Concurrent:
  single_thread:      12.7 Œºs
  2_threads:          ~6.5 Œºs/thread (contention)
  8_threads:          ~10 Œºs/thread (severe contention)
  throughput:         ~10,000 ops/sec

Memory:
  allocations/eval:   ~15
  context_clone:      2.0 Œºs
```

---

## üìä Tracking Progress

### –ü–æ—Å–ª–µ –∫–∞–∂–¥–æ–π P0 –∑–∞–¥–∞—á–∏

```bash
# Run benchmarks
cargo bench --package nebula-expression

# Compare with baseline
cargo bench --package nebula-expression -- --baseline before-p0

# Save new baseline
cargo bench --package nebula-expression -- --save-baseline after-p0.X
```

### Expected improvements

| After Task | Metric | Before | Target | Actual |
|------------|--------|--------|--------|--------|
| P0.1 Template | parse/simple | 10.2Œºs | 2Œºs | ??? |
| P0.2 Engine | concurrent 8t | 10Œºs | 1.3Œºs | ??? |
| P0.3 Context | clone | 2.0Œºs | 50ns | ??? |
| P0.8 Regex | regex match | 10Œºs | 0.1Œºs | ??? |

---

## üî¨ Advanced Profiling

### Flamegraph

```bash
# Install
cargo install flamegraph

# Profile
cargo flamegraph --bench template -- --bench

# Output: flamegraph.svg
```

### DHAT (Heap profiling)

```bash
# Run with DHAT
cargo bench --bench memory

# Analyze dhat-heap.json
```

### Perf (Linux)

```bash
perf record cargo bench --bench engine
perf report
```

---

## üìà Continuous Benchmarking

### GitHub Actions

```yaml
# .github/workflows/benchmark.yml
name: Benchmark

on:
  push:
    branches: [main]
  pull_request:

jobs:
  benchmark:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - uses: actions-rs/toolchain@v1
        with:
          toolchain: stable

      - name: Run benchmarks
        run: cargo bench --package nebula-expression

      - name: Store results
        uses: benchmark-action/github-action-benchmark@v1
        with:
          tool: 'cargo'
          output-file-path: target/criterion/results.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true
```

---

## ‚úÖ Checklist

–ü–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º P0 —Ä–∞–±–æ—Ç—ã:

- [ ] Benchmarks –Ω–∞–ø–∏—Å–∞–Ω—ã
- [ ] Baseline –º–µ—Ç—Ä–∏–∫–∏ —Å–æ–±—Ä–∞–Ω—ã
- [ ] CI –Ω–∞—Å—Ç—Ä–æ–µ–Ω
- [ ] –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∞

–ü–æ—Å–ª–µ –∫–∞–∂–¥–æ–π P0 –∑–∞–¥–∞—á–∏:

- [ ] Benchmarks –∑–∞–ø—É—â–µ–Ω—ã
- [ ] Improvements validated
- [ ] Regression tests pass
- [ ] Metrics documented

---

## üéØ Success Criteria

–ó–∞–¥–∞—á–∞ —Å—á–∏—Ç–∞–µ—Ç—Å—è —É—Å–ø–µ—à–Ω–æ–π –µ—Å–ª–∏:

1. ‚úÖ **Benchmark shows improvement** (—Å–æ–≥–ª–∞—Å–Ω–æ target)
2. ‚úÖ **No regressions** (–¥—Ä—É–≥–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –Ω–µ —É—Ö—É–¥—à–∏–ª–∏—Å—å)
3. ‚úÖ **CI passes** (automated checks)
4. ‚úÖ **Documented** (—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ CHANGELOG)

---

**Next Step**: –°–æ–∑–¥–∞—Ç—å benchmark —Ñ–∞–π–ª—ã –∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å baseline
