# Rust 1.90 Windows Bug - Workaround –¥–ª—è Benchmarking

## üêõ –ü—Ä–æ–±–ª–µ–º–∞

Rust 1.90.0 –∏–º–µ–µ—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π bug –Ω–∞ Windows, –∫–æ—Ç–æ—Ä—ã–π –±–ª–æ–∫–∏—Ä—É–µ—Ç –∫–æ–º–ø–∏–ª—è—Ü–∏—é:

```
error[E0080]: scalar size mismatch: expected X bytes but got Y bytes instead
```

–≠—Ç–æ –∏–∑–≤–µ—Å—Ç–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞:
- https://github.com/rust-lang/rust/issues/XXXXX
- Affects: windows, windows-core, zerocopy crates
- Platform: Windows only
- Version: Rust 1.90.0

**Impact**: –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Criterion –∏ –¥—Ä—É–≥–∏–µ benchmark libraries

---

## ‚úÖ Solution 1: Downgrade Rust (–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

### Option A: Rust 1.85.0

```bash
# Install older version
rustup install 1.85.0

# Set as default
rustup default 1.85.0

# Verify
rustc --version
# Should show: rustc 1.85.0

# Now benchmarks should work
cd crates/nebula-expression
cargo bench
```

### Option B: Nightly (–µ—Å–ª–∏ 1.85 –Ω–µ –ø–æ–º–æ–≥–∞–µ—Ç)

```bash
rustup default nightly

# Verify
rustc --version
# Should show: rustc 1.XX.0-nightly

# Try benchmarks
cargo bench
```

---

## ‚úÖ Solution 2: Manual Benchmarking (–¢–µ–∫—É—â–∏–π –ø–æ–¥—Ö–æ–¥)

–¢–∞–∫ –∫–∞–∫ downgrade –º–æ–∂–µ—Ç –Ω–µ –±—ã—Ç—å –æ–ø—Ü–∏–µ–π (CI/CD constraints), –∏—Å–ø–æ–ª—å–∑—É–µ–º **manual timing**:

### –°–æ–∑–¥–∞—Ç—å manual benchmark helper

```rust
// crates/nebula-expression/tests/manual_benchmarks.rs

use std::time::{Duration, Instant};

const ITERATIONS: usize = 1000;

fn bench<F>(name: &str, mut f: F)
where
    F: FnMut(),
{
    // Warmup
    for _ in 0..100 {
        f();
    }

    // Measure
    let start = Instant::now();
    for _ in 0..ITERATIONS {
        f();
    }
    let duration = start.elapsed();

    let avg = duration / ITERATIONS as u32;
    println!("{:40} {:>10.2?}", name, avg);
}

#[test]
#[ignore]
fn baseline_benchmarks() {
    use nebula_expression::*;
    use nebula_value::Value;

    println!("\n{:=^52}", " BASELINE ");

    // Template parse
    bench("template/parse/simple", || {
        let _ = Template::new("Hello {{ $input }}!");
    });

    // Engine eval
    let engine = ExpressionEngine::new();
    let context = EvaluationContext::new();
    bench("engine/eval/arithmetic", || {
        let _ = engine.evaluate("2 + 3 * 4", &context);
    });

    println!("{:=^52}\n", "");
}
```

### –ó–∞–ø—É—Å–∫

```bash
# Run manual benchmarks
cargo test --release manual_benchmarks -- --ignored --nocapture --test-threads=1

# Redirect to file
cargo test --release manual_benchmarks -- --ignored --nocapture --test-threads=1 > baseline.txt
```

---

## ‚úÖ Solution 3: Linux/macOS –¥–ª—è Benchmarks

–ï—Å–ª–∏ –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø –∫ Linux/macOS:

```bash
# –ù–∞ Linux/macOS Rust 1.90 —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ
cargo bench

# Or use WSL on Windows
wsl
cd /mnt/c/Users/vanya/RustroverProjects/nebula
cargo bench
```

---

## üìä Manual Benchmarking Guide

### 1. Baseline Template

–°–æ–∑–¥–∞—Ç—å `crates/nebula-expression/tests/manual_benchmarks.rs`:

```rust
use nebula_expression::{Template, ExpressionEngine, EvaluationContext};
use nebula_value::Value;
use std::time::Instant;

const ITERS: usize = 1000;

fn avg_time<F: FnMut()>(mut f: F) -> std::time::Duration {
    // Warmup
    for _ in 0..100 { f(); }

    // Measure
    let start = Instant::now();
    for _ in 0..ITERS { f(); }
    start.elapsed() / ITERS as u32
}

#[test]
#[ignore]
fn benchmark_baseline() {
    println!("\n=== BASELINE BENCHMARKS ===\n");

    // Template benchmarks
    println!("üìù Template:");
    println!("  parse/simple:  {:?}", avg_time(|| {
        Template::new("Hello {{ $input }}!").unwrap();
    }));

    let engine = ExpressionEngine::new();
    let mut ctx = EvaluationContext::new();
    ctx.set_input(Value::text("World"));
    let tmpl = Template::new("Hello {{ $input }}!").unwrap();

    println!("  render/simple: {:?}", avg_time(|| {
        tmpl.render(&engine, &ctx).unwrap();
    }));

    println!("  clone:         {:?}", avg_time(|| {
        let _ = tmpl.clone();
    }));

    // Engine benchmarks
    println!("\n‚öôÔ∏è  Engine:");
    let ctx2 = EvaluationContext::new();

    println!("  eval/literal:    {:?}", avg_time(|| {
        engine.evaluate("42", &ctx2).unwrap();
    }));

    println!("  eval/arithmetic: {:?}", avg_time(|| {
        engine.evaluate("2 + 3 * 4", &ctx2).unwrap();
    }));

    // Context benchmarks
    println!("\nüì¶ Context:");
    let mut big_ctx = EvaluationContext::new();
    for i in 0..100 {
        big_ctx.set_execution_var(format!("var_{}", i), Value::integer(i));
    }

    println!("  clone_100:   {:?}", avg_time(|| {
        let _ = big_ctx.clone();
    }));

    // Concurrent benchmark
    println!("\nüîÄ Concurrent:");
    use std::sync::Arc;
    use std::thread;

    let arc_engine = Arc::new(ExpressionEngine::with_cache_size(1000));
    let expr = "2 + 2";

    // Warm cache
    let _ = arc_engine.evaluate(expr, &ctx2);

    println!("  1_thread:  {:?}", avg_time(|| {
        let _ = arc_engine.evaluate(expr, &ctx2);
    }));

    let start = Instant::now();
    for _ in 0..ITERS {
        let handles: Vec<_> = (0..8)
            .map(|_| {
                let eng = Arc::clone(&arc_engine);
                thread::spawn(move || {
                    let c = EvaluationContext::new();
                    for _ in 0..10 {
                        let _ = eng.evaluate(expr, &c);
                    }
                })
            })
            .collect();
        for h in handles {
            h.join().unwrap();
        }
    }
    println!("  8_threads: {:?}", start.elapsed() / ITERS as u32);

    println!("\n===========================\n");
}
```

### 2. Run and Save Results

```bash
# Run once to see results
cargo test --release benchmark_baseline -- --ignored --nocapture

# Save to file
cargo test --release benchmark_baseline -- --ignored --nocapture > BASELINE-RESULTS.txt 2>&1

# Add to git
git add BASELINE-RESULTS.txt
git commit -m "docs: add baseline benchmark results"
```

### 3. After Each P0 Task

```bash
# Run again
cargo test --release benchmark_baseline -- --ignored --nocapture > AFTER-P0.X-RESULTS.txt

# Compare
diff BASELINE-RESULTS.txt AFTER-P0.1-RESULTS.txt
```

---

## üìà Example Expected Output

```
=== BASELINE BENCHMARKS ===

üìù Template:
  parse/simple:  10.2Œºs
  render/simple: 8.5Œºs
  clone:         2.1Œºs

‚öôÔ∏è  Engine:
  eval/literal:    15.3Œºs
  eval/arithmetic: 48.7Œºs

üì¶ Context:
  clone_100:   2.0Œºs

üîÄ Concurrent:
  1_thread:  12.7Œºs
  8_threads: 9.8Œºs

===========================
```

---

## ‚úÖ Recommended Approach

**For now (Rust 1.90 bug exists)**:

1. ‚úÖ Use manual benchmarks (Solution 2)
2. ‚úÖ Run on release mode: `cargo test --release`
3. ‚úÖ Save results to files
4. ‚úÖ Manual comparison between runs

**Long term (when bug fixed)**:

1. ‚è≥ Wait for Rust 1.91 or fix in 1.90.1
2. ‚è≥ Switch to Criterion
3. ‚è≥ Automated CI benchmarking

---

## üìù Progress Tracking

### Manual Benchmark Results Format

```markdown
## Baseline (Before P0)
Date: 2025-01-08
Rust: 1.90.0 (manual benchmarks due to Windows bug)

| Benchmark | Time |
|-----------|------|
| template/parse/simple | 10.2Œºs |
| template/render/simple | 8.5Œºs |
| template/clone | 2.1Œºs |
| engine/eval/arithmetic | 48.7Œºs |
| context/clone_100 | 2.0Œºs |
| concurrent/1_thread | 12.7Œºs |
| concurrent/8_threads | 9.8Œºs |

## After P0.1 (Template Zero-Copy)
Date: 2025-01-09

| Benchmark | Before | After | Improvement |
|-----------|--------|-------|-------------|
| template/parse/simple | 10.2Œºs | 2.1Œºs | 4.86x ‚úÖ |
| template/clone | 2.1Œºs | 48ns | 43.75x ‚úÖ |
```

---

## üîÑ Alternative: Docker with Linux

```dockerfile
# Dockerfile.benchmark
FROM rust:1.90

WORKDIR /app
COPY . .

RUN cargo bench
```

```bash
# Build and run
docker build -f Dockerfile.benchmark -t nebula-bench .
docker run nebula-bench
```

---

## üéØ Bottom Line

**–¢–µ–∫—É—â–µ–µ —Ä–µ—à–µ–Ω–∏–µ**:
- ‚úÖ Manual benchmarks —Ä–∞–±–æ—Ç–∞—é—Ç
- ‚úÖ –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ—á–Ω–æ—Å—Ç–∏ –¥–ª—è P0 —É–ª—É—á—à–µ–Ω–∏–π
- ‚úÖ –ù–µ —Ç—Ä–µ–±—É—é—Ç downgrade Rust

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è**:
1. –ò—Å–ø–æ–ª—å–∑—É–π manual benchmarks (tests/manual_benchmarks.rs)
2. –ó–∞–ø—É—Å–∫–∞–π —Å `--release` –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
3. –°–æ—Ö—Ä–∞–Ω—è–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª—ã
4. –°—Ä–∞–≤–Ω–∏–≤–∞–π –≤—Ä—É—á–Ω—É—é (diff –∏–ª–∏ —Ç–∞–±–ª–∏—Ü—ã)

**Good enough –¥–ª—è Phase 0!** üöÄ

---

**Last Updated**: 2025-01-08
**Status**: Workaround Active
**Tracking Issue**: Rust #XXXXX (Windows scalar size mismatch)
